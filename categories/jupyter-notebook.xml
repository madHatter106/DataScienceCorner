<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Erdem K's DS corner (Jupyter notebook)</title><link>https://madhatter106.github.io/</link><description></description><atom:link type="application/rss+xml" rel="self" href="https://madhatter106.github.io/DataScienceCorner/categories/jupyter-notebook.xml"></atom:link><language>en</language><lastBuildDate>Mon, 20 Feb 2017 16:53:27 GMT</lastBuildDate><generator>https://getnikola.com/</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>XARRAY &amp; GEOVIEWS A new perspective on oceanographic data - part I</title><link>https://madhatter106.github.io/DataScienceCorner/posts/xarray-geoviews-a-new-perspective-on-oceanographic-data-part-i/</link><dc:creator>Erdem Karakoylu</dc:creator><description>&lt;div tabindex="-1" id="notebook" class="border-box-sizing"&gt;
    &lt;div class="container" id="notebook-container"&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;With this post I explore an alternative to ol' numpy; &lt;a href="http://xarray.pydata.org/en/stable/index.html"&gt;xarray&lt;/a&gt;. This is a very handy library that purports to apply the pandas concept of labeled dimension to large data arrays for scientific computation. In addition to the resulting ease of manipulation of dimensions without having to guess what they correspond to, xarray plays nicely with two other relatively new libraries:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://dask.pydata.org/en/latest/"&gt;dask&lt;/a&gt;, which enables out of core computation so that memory availability becomes much less an issue; &lt;/li&gt;
&lt;li&gt;&lt;a href="http://geo.holoviews.org/"&gt;GeoViews&lt;/a&gt;, a library sitting on top of &lt;a href="http://holoviews.org/"&gt;HoloViews&lt;/a&gt;. The latter eases the burden of data visualization by offering an unusual approach that does away with step-by-step graphical coding and allows the user to concentrate how the data organization instead. This results in a substantial reduction code written, which makes data analysis much cleaner and less bug-prone. GeoViews sits on top of the visualization package HoloViews, with an emphasis on geophysical data. It's also my first good-bye to the aging (10+ years) matplotlib library. It'll still be handy now and then, but it's time to try new things. &lt;p&gt;&lt;a href="https://madhatter106.github.io/DataScienceCorner/posts/xarray-geoviews-a-new-perspective-on-oceanographic-data-part-i/"&gt;Read more…&lt;/a&gt; (5 min remaining to read)&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>Jupyter notebook</category><category>ocean color</category><category>xarray</category><guid>https://madhatter106.github.io/DataScienceCorner/posts/xarray-geoviews-a-new-perspective-on-oceanographic-data-part-i/</guid><pubDate>Mon, 20 Feb 2017 16:16:55 GMT</pubDate></item><item><title>Titanic Diaries - Part I: Data Dusting</title><link>https://madhatter106.github.io/DataScienceCorner/posts/titanic-i-cleanup/</link><dc:creator>Erdem Karakoylu</dc:creator><description>&lt;div tabindex="-1" id="notebook" class="border-box-sizing"&gt;
    &lt;div class="container" id="notebook-container"&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;In most data science tutorials I have seen, a lot of the data clean-up is done in what seems to me casually, an annoying obstacle to get to the sexy Machine Learning bit. I was curious to see what if any difference it made in my Kaggle ranking if I used a somewhat more cautious approach in my data cleanup. My approach was to dumbly follow &lt;a href="https://www.datacamp.com/community/open-courses/kaggle-python-tutorial-on-machine-learning#gs.EkI78Vw"&gt;Datacamp's tutorial&lt;/a&gt; and submit my test set labels as a benchmark. The second step is then to use a more elaborate data cleanup process and see whether taking the extra time actually moves my ranking up, or maybe down.
&lt;/p&gt;&lt;p&gt;&lt;a href="https://madhatter106.github.io/DataScienceCorner/posts/titanic-i-cleanup/"&gt;Read more…&lt;/a&gt; (12 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>Ipython</category><category>Jupyter notebook</category><category>kaggle</category><category>titanic</category><guid>https://madhatter106.github.io/DataScienceCorner/posts/titanic-i-cleanup/</guid><pubDate>Mon, 09 Jan 2017 21:46:09 GMT</pubDate></item></channel></rss>