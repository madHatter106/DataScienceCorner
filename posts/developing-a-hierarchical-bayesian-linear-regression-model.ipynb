{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following a previous [post](), I use the historically accurate dataset behind the development of NASA OBPG's chlorophyll algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as pl\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import pymc3 as pm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ParseTextFile(textFileHandle, topickle=False, convert2DateTime=False, **kwargs):\n",
    "    \"\"\"\n",
    "    * topickle: pickle resulting DataFrame if True\n",
    "    * convert2DateTime: join date/time columns and convert entries to datetime objects\n",
    "    * kwargs:\n",
    "        pkl_fname: pickle file name to save DataFrame by, if topickle=True\n",
    "    \"\"\"\n",
    "    # Pre-compute some regex\n",
    "    columns = re.compile('^/fields=(.+)') # to get field/column names\n",
    "    units = re.compile('^/units=(.+)') # to get units -- optional\n",
    "    endHeader = re.compile('^/end_header') # to know when to start storing data\n",
    "    # Set some milestones\n",
    "    noFields = True\n",
    "    getData = False\n",
    "    # loop through the text data\n",
    "    for line in textFileHandle:\n",
    "        if noFields:\n",
    "            fieldStr = columns.findall(line)\n",
    "            if len(fieldStr)>0:\n",
    "                noFields = False\n",
    "                fieldList = fieldStr[0].split(',')\n",
    "                dataDict = dict.fromkeys(fieldList)\n",
    "                continue # nothing left to do with this line, keep looping\n",
    "        if not getData:\n",
    "            if endHeader.match(line):\n",
    "                # end of header reached, start acquiring data\n",
    "                getData = True \n",
    "        else:\n",
    "            dataList = line.split(',')\n",
    "            for field,datum in zip(fieldList, dataList):\n",
    "                if not dataDict[field]:\n",
    "                    dataDict[field] = []\n",
    "                dataDict[field].append(datum)\n",
    "    df = pd.DataFrame(dataDict, columns=fieldList)\n",
    "    if convert2DateTime:\n",
    "        datetimelabels=['year', 'month', 'day', 'hour', 'minute', 'second']\n",
    "        df['Datetime']= pd.to_datetime(df[datetimelabels],\n",
    "                                       format='%Y-%m-%dT%H:%M:%S')\n",
    "        df.drop(datetimelabels, axis=1, inplace=True)\n",
    "    if topickle:\n",
    "        fname=kwargs.pop('pkl_fname', 'dfNomad2.pkl')\n",
    "        df.to_pickle(fname)\n",
    "    return df\n",
    "\n",
    "def FindNaNs(df):\n",
    "    for col in df.columns:\n",
    "        sn = np.where(df[col].values=='NaN', True, False).sum()\n",
    "        s9 = np.where('-999' in df[col].values, True, False).sum()\n",
    "        print(\"%s: %d NaNs & %d -999s\" % (col, sn, s9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/accounts/ekarakoy/DATA/ocprep_v4_iop.txt') as fdata:\n",
    "    df = ParseTextFile(fdata, topickle=True, convert2DateTime=True,\n",
    "                       pkl_fname='JeremyOCx_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.info() # skipping output which shows a lot of unnecessary features for this exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "basicCols = ['cruise', 'lat', 'lon', 'type', 'chl', 'Datetime']\n",
    "IwantCols = basicCols + [col for col in df.columns if 'rrs' in col]\n",
    "dfRrs = df[IwantCols]\n",
    "swflbls = ['rrs411','rrs443','rrs489','rrs510','rrs555','rrs670']\n",
    "swfCols = basicCols + swflbls\n",
    "dfSwf = dfRrs[swfCols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "savDir = '/accounts/ekarakoy/DEV-ALL/BLOGS/DataScienceCorner/posts/bayesianChl_stuff/'\n",
    "df.to_pickle(os.path.join(savDir, 'dfOcPrepHistoric.pkl'))\n",
    "dfRrs.to_pickle(os.path.join(savDir, 'dfOcPrepRrs.pkl'))\n",
    "del df, dfRrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2483 entries, 0 to 2482\n",
      "Data columns (total 12 columns):\n",
      "cruise      2483 non-null object\n",
      "lat         2483 non-null object\n",
      "lon         2483 non-null object\n",
      "type        2483 non-null object\n",
      "chl         2483 non-null object\n",
      "Datetime    2483 non-null datetime64[ns]\n",
      "rrs411      2483 non-null object\n",
      "rrs443      2483 non-null object\n",
      "rrs489      2483 non-null object\n",
      "rrs510      2483 non-null object\n",
      "rrs555      2483 non-null object\n",
      "rrs670      2483 non-null object\n",
      "dtypes: datetime64[ns](1), object(11)\n",
      "memory usage: 232.9+ KB\n"
     ]
    }
   ],
   "source": [
    "dfSwf.info() # skipping the output which shows that most columns are object type..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cruise: 0 NaNs & 0 -999s\n",
      "lat: 0 NaNs & 0 -999s\n",
      "lon: 0 NaNs & 0 -999s\n",
      "type: 0 NaNs & 0 -999s\n",
      "chl: 535 NaNs & 0 -999s\n",
      "Datetime: 0 NaNs & 0 -999s\n",
      "rrs411: 22 NaNs & 0 -999s\n",
      "rrs443: 0 NaNs & 0 -999s\n",
      "rrs489: 0 NaNs & 0 -999s\n",
      "rrs510: 0 NaNs & 0 -999s\n",
      "rrs555: 0 NaNs & 0 -999s\n",
      "rrs670: 0 NaNs & 0 -999s\n"
     ]
    }
   ],
   "source": [
    "FindNaNs(dfSwf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1931 entries, 0 to 2482\n",
      "Data columns (total 12 columns):\n",
      "cruise      1931 non-null object\n",
      "lat         1931 non-null float64\n",
      "lon         1931 non-null float64\n",
      "type        1931 non-null object\n",
      "chl         1931 non-null float64\n",
      "Datetime    1931 non-null datetime64[ns]\n",
      "rrs411      1931 non-null float64\n",
      "rrs443      1931 non-null float64\n",
      "rrs489      1931 non-null float64\n",
      "rrs510      1931 non-null float64\n",
      "rrs555      1931 non-null float64\n",
      "rrs670      1931 non-null float64\n",
      "dtypes: datetime64[ns](1), float64(9), object(2)\n",
      "memory usage: 196.1+ KB\n"
     ]
    }
   ],
   "source": [
    "dfSwf.replace(to_replace='NaN',value=np.NaN,inplace=True)\n",
    "dfSwf.dropna(inplace=True)\n",
    "numCols = ['chl','lat','lon','rrs411','rrs443','rrs489','rrs510','rrs555','rrs670']\n",
    "dfSwf[numCols] = dfSwf[numCols].apply(pd.to_numeric)\n",
    "dfSwf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "nikola": {
   "category": "",
   "date": "2017-03-22 14:17:11 UTC-04:00",
   "description": "",
   "link": "",
   "slug": "developing-a-hierarchical-bayesian-linear-regression-model",
   "tags": "",
   "title": "Developing a Hierarchical Bayesian Linear Regression Model",
   "type": "text"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
