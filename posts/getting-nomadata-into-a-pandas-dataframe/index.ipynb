{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this post, I'm going to briefly describe how a I download the [NASA bio-Optical Marine Algorithm Dataset or NOMAD](https://seabass.gsfc.nasa.gov/wiki/NOMAD) created for algorithm development, extract the data I need and store it all neatly in a Pandas DataFrame. Here I use the latest dataset, NOMAD v.2, created in 2008.\n",
    "<!-- Teaser_End -->\n",
    "First things first; imports!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data can be accessed through a URL that I'll store in a string below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NOMADV2url='https://seabass.gsfc.nasa.gov/wiki/NOMAD/nomad_seabass_v2.a_2008200.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I'll write a couple of functions. The first to get the data from the url. The second function will parse the text returned by the first function and put in a Pandas DataFrame. This second function makes more sense after inspecting the content of the page at the url above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetNomad(url=NOMADV2url):\n",
    "    \"\"\"Download and return data as text\"\"\"\n",
    "    resp = requests.get(NOMADV2url)\n",
    "    content = resp.text.splitlines()    \n",
    "    resp.close()\n",
    "    return content\n",
    "\n",
    "def ParseTextFile(textFile, topickle=False, convert2DateTime=False, **kwargs):\n",
    "    \"\"\"\n",
    "    * topickle: pickle resulting DataFrame if True\n",
    "    * convert2DateTime: join date/time columns and convert entries to datetime objects\n",
    "    * kwargs:\n",
    "        pkl_fname: pickle file name to save DataFrame by, if topickle=True\n",
    "    \"\"\"\n",
    "    # Pre-compute some regex\n",
    "    columns = re.compile('^/fields=(.+)') # to get field/column names\n",
    "    units = re.compile('^/units=(.+)') # to get units -- optional\n",
    "    endHeader = re.compile('^/end_header') # to know when to start storing data\n",
    "    # Set some milestones\n",
    "    noFields = True\n",
    "    getData = False\n",
    "    # loop through the text data\n",
    "    for line in textFile:\n",
    "        if noFields:\n",
    "            fieldStr = columns.findall(line)\n",
    "            if len(fieldStr)>0:\n",
    "                noFields = False\n",
    "                fieldList = fieldStr[0].split(',')\n",
    "                dataDict = dict.fromkeys(fieldList)\n",
    "                continue # nothing left to do with this line, keep looping\n",
    "        if not getData:\n",
    "            if endHeader.match(line):\n",
    "                # end of header reached, start acquiring data\n",
    "                getData = True \n",
    "        else:\n",
    "            dataList = line.split(',')\n",
    "            for field,datum in zip(fieldList, dataList):\n",
    "                if not dataDict[field]:\n",
    "                    dataDict[field] = []\n",
    "                dataDict[field].append(datum)\n",
    "    df = pd.DataFrame(dataDict, columns=fieldList)\n",
    "    if convert2DateTime:\n",
    "        datetimelabels=['year', 'month', 'day', 'hour', 'minute', 'second']\n",
    "        df['Datetime']= pd.to_datetime(df[datetimelabels],\n",
    "                                       format='%Y-%m-%dT%H:%M:%S')\n",
    "        df.drop(datetimelabels, axis=1, inplace=True)\n",
    "    if topickle:\n",
    "        fname=kwargs.pop('pkl_fname', 'dfNomad2.pkl')\n",
    "        df.to_pickle(fname)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = ParseTextFile(GetNomad(), topickle=True, convert2DateTime=True,\n",
    "                  pkl_fname='/accounts/ekarakoy/DATA/dfNomadRaw.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>id</th>\n",
       "      <th>oisst</th>\n",
       "      <th>etopo2</th>\n",
       "      <th>chl</th>\n",
       "      <th>chl_a</th>\n",
       "      <th>kd405</th>\n",
       "      <th>kd411</th>\n",
       "      <th>kd443</th>\n",
       "      <th>...</th>\n",
       "      <th>diato</th>\n",
       "      <th>lut</th>\n",
       "      <th>zea</th>\n",
       "      <th>chl_b</th>\n",
       "      <th>beta-car</th>\n",
       "      <th>alpha-car</th>\n",
       "      <th>alpha-beta-car</th>\n",
       "      <th>flag</th>\n",
       "      <th>cruise</th>\n",
       "      <th>Datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38.4279</td>\n",
       "      <td>-76.61</td>\n",
       "      <td>1565</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.19</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>3.9455</td>\n",
       "      <td>3.1457</td>\n",
       "      <td>...</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>20691</td>\n",
       "      <td>ace0301</td>\n",
       "      <td>2003-04-15 15:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.368</td>\n",
       "      <td>-76.5</td>\n",
       "      <td>1566</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.01</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>2.5637</td>\n",
       "      <td>2.0529</td>\n",
       "      <td>...</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>20675</td>\n",
       "      <td>ace0301</td>\n",
       "      <td>2003-04-15 16:50:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38.3074</td>\n",
       "      <td>-76.44</td>\n",
       "      <td>1567</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1</td>\n",
       "      <td>26.91</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>2.1533</td>\n",
       "      <td>1.7531</td>\n",
       "      <td>...</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>20691</td>\n",
       "      <td>ace0301</td>\n",
       "      <td>2003-04-15 17:50:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38.6367</td>\n",
       "      <td>-76.32</td>\n",
       "      <td>1568</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3</td>\n",
       "      <td>47.96</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>2.69</td>\n",
       "      <td>2.2985</td>\n",
       "      <td>...</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>20675</td>\n",
       "      <td>ace0301</td>\n",
       "      <td>2003-04-17 18:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38.3047</td>\n",
       "      <td>-76.44</td>\n",
       "      <td>1559</td>\n",
       "      <td>22.03</td>\n",
       "      <td>1</td>\n",
       "      <td>23.55</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>3.095</td>\n",
       "      <td>2.3966</td>\n",
       "      <td>...</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>20691</td>\n",
       "      <td>ace0302</td>\n",
       "      <td>2003-07-21 18:27:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 212 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       lat     lon    id  oisst etopo2    chl chl_a kd405   kd411   kd443  \\\n",
       "0  38.4279  -76.61  1565    3.7    0.0  38.19  -999  -999  3.9455  3.1457   \n",
       "1   38.368   -76.5  1566    3.7    0.0  35.01  -999  -999  2.5637  2.0529   \n",
       "2  38.3074  -76.44  1567    3.7      1  26.91  -999  -999  2.1533  1.7531   \n",
       "3  38.6367  -76.32  1568    3.7      3  47.96  -999  -999    2.69  2.2985   \n",
       "4  38.3047  -76.44  1559  22.03      1  23.55  -999  -999   3.095  2.3966   \n",
       "\n",
       "          ...         diato   lut   zea chl_b beta-car alpha-car  \\\n",
       "0         ...          -999  -999  -999  -999     -999      -999   \n",
       "1         ...          -999  -999  -999  -999     -999      -999   \n",
       "2         ...          -999  -999  -999  -999     -999      -999   \n",
       "3         ...          -999  -999  -999  -999     -999      -999   \n",
       "4         ...          -999  -999  -999  -999     -999      -999   \n",
       "\n",
       "  alpha-beta-car   flag   cruise            Datetime  \n",
       "0           -999  20691  ace0301 2003-04-15 15:15:00  \n",
       "1           -999  20675  ace0301 2003-04-15 16:50:00  \n",
       "2           -999  20691  ace0301 2003-04-15 17:50:00  \n",
       "3           -999  20675  ace0301 2003-04-17 18:15:00  \n",
       "4           -999  20691  ace0302 2003-07-21 18:27:00  \n",
       "\n",
       "[5 rows x 212 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This DataFrame quite large and unwieldy with 212 columns. But Pandas makes it easy to extract the necessary data for a particular project. For my current project, which I'll go over in a subsequent post, I need field data relevant to the [SeaWiFS sensor](https://en.wikipedia.org/wiki/SeaWiFS), in particular optical data at wavelengths 412, 443, 490, 510, 555, and 670 nm. First let's look at the available bands as they appear in spectral surface irradiance column labels, which start with 'es'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['405', '411', '443', '455', '465', '489', '510', '520', '530', '550', '555', '560', '565', '570', '590', '619', '625', '665', '670', '683']\n"
     ]
    }
   ],
   "source": [
    "bandregex = re.compile('es([0-9]+)')\n",
    "bands = bandregex.findall(''.join(df.columns))\n",
    "print(bands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I can extract data with bands that are the closest to what I need. In the process I'm going to use water leaving radiance and spectral surface irradiance to compute remote sensing reflectance, rrs. I will store this new data in a new DataFrame, dfSwf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "swfBands = ['411','443','489','510','555','670']\n",
    "dfSwf = pd.DataFrame(columns=['rrs%s' % b for b in swfBands])\n",
    "for b in swfBands:\n",
    "    dfSwf.loc[:,'rrs%s'%b] = df.loc[:,'lw%s' % b].astype('f8') / df.loc[:,'es%s' % b].astype('f8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rrs411</th>\n",
       "      <th>rrs443</th>\n",
       "      <th>rrs489</th>\n",
       "      <th>rrs510</th>\n",
       "      <th>rrs555</th>\n",
       "      <th>rrs670</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001204</td>\n",
       "      <td>0.001686</td>\n",
       "      <td>0.003293</td>\n",
       "      <td>0.004036</td>\n",
       "      <td>0.007479</td>\n",
       "      <td>0.003465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001062</td>\n",
       "      <td>0.001384</td>\n",
       "      <td>0.002173</td>\n",
       "      <td>0.002499</td>\n",
       "      <td>0.004152</td>\n",
       "      <td>0.001695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000971</td>\n",
       "      <td>0.001185</td>\n",
       "      <td>0.001843</td>\n",
       "      <td>0.002288</td>\n",
       "      <td>0.004246</td>\n",
       "      <td>0.001612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001472</td>\n",
       "      <td>0.001741</td>\n",
       "      <td>0.002877</td>\n",
       "      <td>0.003664</td>\n",
       "      <td>0.006982</td>\n",
       "      <td>0.003234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000905</td>\n",
       "      <td>0.001022</td>\n",
       "      <td>0.001506</td>\n",
       "      <td>0.001903</td>\n",
       "      <td>0.002801</td>\n",
       "      <td>0.001791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     rrs411    rrs443    rrs489    rrs510    rrs555    rrs670\n",
       "0  0.001204  0.001686  0.003293  0.004036  0.007479  0.003465\n",
       "1  0.001062  0.001384  0.002173  0.002499  0.004152  0.001695\n",
       "2  0.000971  0.001185  0.001843  0.002288  0.004246  0.001612\n",
       "3  0.001472  0.001741  0.002877  0.003664  0.006982  0.003234\n",
       "4  0.000905  0.001022  0.001506  0.001903  0.002801  0.001791"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfSwf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My project is about developing a bayesian framework for estimating biological variables using remote sensing data. So I'll need to copy over a few more features from the inital dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfSwf['id'] = df.id.astype('i4') # in case I need to relate this data to the original\n",
    "dfSwf['datetime'] = df.Datetime\n",
    "dfSwf['hplc_chl'] = df.chl_a.astype('f8')\n",
    "dfSwf['fluo_chl'] = df.chl.astype('f8')\n",
    "dfSwf['lat'] = df.lat.astype('f8')\n",
    "dfSwf['lon'] = df.lon.astype('f8')\n",
    "dfSwf['depth'] = df.etopo2.astype('f8')\n",
    "dfSwf['sst'] = df.oisst.astype('f8')\n",
    "for band in swfBands:\n",
    "    addprods=['a','ad','ag','ap','bb']\n",
    "    for prod in addprods:\n",
    "        dfSwf['%s%s' % (prod,band)] = df['%s%s' % (prod, band)].astype('f8')\n",
    "dfSwf.replace(-999,np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tallying the features I've gathered..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['rrs411', 'rrs443', 'rrs489', 'rrs510', 'rrs555', 'rrs670', 'id',\n",
      "       'datetime', 'hplc_chl', 'fluo_chl', 'lat', 'lon', 'depth', 'sst',\n",
      "       'a411', 'ad411', 'ag411', 'ap411', 'bb411', 'a443', 'ad443', 'ag443',\n",
      "       'ap443', 'bb443', 'a489', 'ad489', 'ag489', 'ap489', 'bb489', 'a510',\n",
      "       'ad510', 'ag510', 'ap510', 'bb510', 'a555', 'ad555', 'ag555', 'ap555',\n",
      "       'bb555', 'a670', 'ad670', 'ag670', 'ap670', 'bb670'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(dfSwf.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That seems like a good dataset to start with. I'll pickle this DataFrame for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfSwf.to_pickle('/accounts/ekarakoy/DATA/dfNomadSWF.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it. Until next time, *Happy Hacking!*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "nikola": {
   "category": "",
   "date": "2017-03-15 14:10:25 UTC-04:00",
   "description": "",
   "link": "",
   "slug": "getting-nomadata-into-a-pandas-dataframe",
   "tags": "ocean color, pandas, chlorophyll",
   "title": "Getting NOMAData into a Pandas DataFrame",
   "type": "text"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
